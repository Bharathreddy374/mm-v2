# ğŸ¤– MM-V2 â€” AI-Powered Mock Interview App

> A local AI-driven mock interview web application that helps users practice real interviews.  
> Generates questions, records spoken answers, evaluates them using AI, and provides spoken feedback â€” all in one place.  
> Built with **Next.js**, **TailwindCSS**, **Express**, **MongoDB**, **AssemblyAI (STT)**, **ElevenLabs (TTS)**, and **Groq (Evaluation + Question Generation)**.

---

## ğŸ”— Repository Structure


mm-v2/
â”œâ”€â”€ app/ # Next.js frontend (TypeScript)
â”‚ â”œâ”€â”€ components/
â”‚ â”œâ”€â”€ app/ or pages/
â”‚ â””â”€â”€ package.json
â”œâ”€â”€ my-auth-backend/ # Express backend (Auth + AI Routes)
â”‚ â”œâ”€â”€ routes/
â”‚ â”œâ”€â”€ controllers/
â”‚ â””â”€â”€ package.json
â”œâ”€â”€ prisma/ # Database models (if used)
â”œâ”€â”€ public/ # Static assets
â”œâ”€â”€ styles/ # Tailwind styles
â””â”€â”€ README.md

> Project currently runs locally (not deployed).

---

## ğŸ“– Overview

**MM-V2** is a full-stack mock interview platform that simulates a real interview experience.  
Users can log in, choose their preferred **role** and **difficulty level**, and answer questions via **speech**.  
The system then evaluates their responses using AI and provides instant feedback â€” both in text and voice format.

---

## âœ¨ Features

- ğŸ§  **Dynamic Interview Generation** â€” Groq generates domain- and level-specific questions.
- ğŸ—£ï¸ **Speech-to-Text (STT)** â€” Uses **AssemblyAI** to transcribe user voice input.
- ğŸ’¬ **Automated Evaluation** â€” Groq API analyzes user answers and provides feedback.
- ğŸ”Š **Text-to-Speech (TTS)** â€” ElevenLabs generates realistic audio feedback.
- ğŸ” **JWT Authentication** â€” Secure login and user session management.
- ğŸ’¾ **MongoDB Integration** â€” Saves user sessions, scores, and feedback data.
- ğŸ¨ **Modern UI** â€” Built with TailwindCSS and responsive layout.
- âš¡ **Local-first Architecture** â€” Fully functional on a local setup.

---

## ğŸ§  System Workflow

1. User registers or logs in (JWT-based).
2. Selects **role** (e.g., Frontend, ML Engineer) and **difficulty level**.
3. System fetches relevant interview questions (via **Groq**).
4. User answers verbally â†’ audio sent to backend.
5. Backend uses **AssemblyAI** to convert speech â†’ text.
6. Text answer sent to **Groq** for evaluation â†’ feedback generated.
7. Feedback sent to **ElevenLabs** â†’ audio generated and played back.
8. Session data (questions, responses, feedback, scores) saved to **MongoDB**.

---

## ğŸ§© Tech Stack

| Layer | Technologies |
|-------|---------------|
| **Frontend** | Next.js, React, TailwindCSS |
| **Backend** | Node.js, Express |
| **Database** | MongoDB (Mongoose / Prisma) |
| **AI APIs** | AssemblyAI (Speech-to-Text), ElevenLabs (Text-to-Speech), Groq (Evaluation + QG) |
| **Authentication** | JWT |
| **Deployment (Local)** | Node.js + Next.js dev servers |

---

## âš™ï¸ Environment Variables

Create `.env` files in both the backend and frontend directories with the following keys:

### Backend (`my-auth-backend/.env`)
MONGO_URI=your_mongodb_connection_string
JWT_SECRET=super_secret_jwt_key
PORT=5000

AI API Keys

ASSEMBLY_API_KEY=your_assemblyai_key
GROQ_API_KEY=your_groq_api_key
ELEVEN_API_KEY=your_elevenlabs_key
ELEVEN_VOICE_ID=preferred_voice_id

### Frontend (`app/.env.local`)
NEXT_PUBLIC_API_BASE=http://localhost:5000/api


> âš ï¸ Keep API keys private. Do **not** expose them with `NEXT_PUBLIC_` unless necessary.

---

## ğŸš€ Setup & Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/Bharathreddy374/mm-v2.git
cd mm-v2

cd my-auth-backend
npm install
# Add your environment variables in .env
npm run dev   # or: node index.js

cd ../app
npm install
npm run dev
```

| Method | Endpoint                                  | Description                                    |
| ------ | ----------------------------------------- | ---------------------------------------------- |
| `POST` | `/api/auth/register`                      | Register new user                              |
| `POST` | `/api/auth/login`                         | Login and get JWT                              |
| `GET`  | `/api/questions?role=frontend&level=easy` | Get AI-generated questions                     |
| `POST` | `/api/ai/stt`                             | Convert audio â†’ text using AssemblyAI          |
| `POST` | `/api/ai/evaluate`                        | Evaluate text answer with Groq                 |
| `POST` | `/api/ai/tts`                             | Convert feedback text â†’ voice using ElevenLabs |


)

ğŸ§± Future Enhancements

ğŸ“Š Add analytics dashboard for progress tracking.

ğŸ—‚ï¸ Cloud storage for user recordings (AWS S3 / Firebase).

ğŸ§© Real-time streaming STT for instant feedback.

ğŸ” Expand Groq prompt library with domain-based models.

ğŸ§  Adaptive difficulty adjustment based on past scores.

ğŸ‘¨â€ğŸ’» Author

P Bharath Reddy
ğŸ“§ bharathreddy372k4@gmail.com
